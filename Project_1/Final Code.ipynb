{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "    def grayscale(img):\n",
    "        \"\"\"Applies the Grayscale transform\n",
    "         This will return an image with only one color channel\n",
    "        but NOTE: to see the returned image as grayscale\n",
    "        (assuming your grayscaled image is called 'gray')\n",
    "        you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    def gaussian_blur(img, kernel_size):\n",
    "        \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "        return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    def canny(img, low_threshold, high_threshold):\n",
    "        \"\"\"Applies the Canny transform\"\"\"\n",
    "        return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "    def region_of_interest(img, vertices):\n",
    "        \"\"\"\n",
    "         Applies an image mask.\n",
    "    \n",
    "        Only keeps the region of the image defined by the polygon\n",
    "        formed from `vertices`. The rest of the image is set to black.\n",
    "        \"\"\"\n",
    "        #defining a blank mask to start with\n",
    "        mask = np.zeros_like(img)   \n",
    "    \n",
    "        #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "        if len(img.shape) > 2:\n",
    "            channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "        \n",
    "        #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "        #returning the image only where mask pixels are nonzero\n",
    "        masked_image = cv2.bitwise_and(img, mask)\n",
    "        return masked_image\n",
    "\n",
    "    def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "        \"\"\"\n",
    "        `img` should be the output of a Canny transform.\n",
    "        \n",
    "        Returns an image with hough lines drawn.\n",
    "        \"\"\"\n",
    "        lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    \n",
    "        return lines  \n",
    "    def linear_reg(Hough_array, linetype, line_image, out_type):\n",
    "        \n",
    "        '''Applies linear regression for specific slope ranges linetype='r' \n",
    "            for right side line and 'l' for left side lines. '''\n",
    "        \n",
    "        temp_list=[]\n",
    "        for line in Hough_array:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                slope= (y2-y1)/(x2-x1)\n",
    "                if linetype=='l' and slope<-0.5 and slope>-0.8:\n",
    "                    temp_list.append([x1,x2,y1,y2])\n",
    "                    #this condition will execute if we just want to see output like raw_video sampl\n",
    "                    if out_type =='raw':\n",
    "                        cv2.line(line_image, (x1,y1), (x2,y2), [255, 0, 100], 8)\n",
    "                elif linetype=='r' and slope>0.5 and slope<0.8:\n",
    "                    temp_list.append([x1,x2,y1,y2])\n",
    "                    if out_type =='raw':\n",
    "                        cv2.line(line_image, (x1,y1), (x2,y2), [255, 0,100], 8)\n",
    "        temp = np.array(temp_list)\n",
    "        X=np.reshape(temp[:,[0,1]], (1,len(temp)*2))[0]\n",
    "        A = np.vstack([X,np.ones(len(X))]).T\n",
    "        Y = np.reshape(temp[:, [2, 3]], (1, len(temp) * 2))[0]\n",
    "        m, c = np.linalg.lstsq(A, Y)[0]\n",
    "        X= np.array(X)\n",
    "        Y = np.array(X * m + c)\n",
    "        minY= Y.min()\n",
    "        maxY= Y.max()\n",
    "        return minY, maxY,m,c,line_image\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "     #Converting the image to grayscale\n",
    "    gray = grayscale(image)\n",
    "    \n",
    "    \n",
    "    #Applying gaussian blur to the grayscale image\n",
    "    kernel_size = 7\n",
    "    blur_gray = gaussian_blur(gray, kernel_size)\n",
    "    \n",
    "    \n",
    "    # Define our parameters for Canny and run it\n",
    "    low_threshold =50\n",
    "    high_threshold = 200\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # Next we'll create a masked edges image using cv2.fillPoly()\n",
    "    \n",
    "    vertices_left = np.array([[(40,500),(390, 350), (500, 350), (500,500)]], dtype=np.int32)\n",
    "    vertices_right = np.array([[(940,500),(650, 350), (500, 350), (500,500)]], dtype=np.int32)\n",
    "   \n",
    "    masked_edges_left = region_of_interest(edges, vertices_left)\n",
    "    masked_edges_right = region_of_interest(edges, vertices_right)\n",
    "    \n",
    "        # Make a blank the same size as our image to draw on\n",
    "    rho = 2 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 10    # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length =10 #minimum number of pixels making up a line\n",
    "    max_line_gap = 15  # maximum gap in pixels between connectable line segments 15\n",
    "\n",
    "    line_image = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "  \n",
    "    \n",
    "    # Apply Hough's transform for left side and right side lines\n",
    "    hough_lines_left = hough_lines(masked_edges_left, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    hough_lines_right = hough_lines(masked_edges_right, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    \n",
    "    #Run linear regression for selected slope range \n",
    "    minY_right, maxY_right, m_right, c_right, line_image = linear_reg(hough_lines_right, 'r', line_image, 0)\n",
    "    minY_left, maxY_left, m_left, c_left, line_image = linear_reg(hough_lines_left, 'l',line_image, 0)\n",
    "    \n",
    "    # Determine the upper and lower points to draw a line in the image\n",
    "    min_y = np.min([minY_left, minY_right])\n",
    "    upper_right_pt = np.array([(min_y - c_right) / m_right, min_y], dtype=int)\n",
    "    upper_left_pt = np.array([(min_y - c_left) / m_left, min_y], dtype=int)\n",
    "    max_y = np.max([maxY_left,maxY_right])\n",
    "    lower_left_pt = np.array([(max_y - c_left) / m_left, max_y], dtype=int)\n",
    "    lower_right_pt = np.array([(max_y - c_right) / m_right, max_y], dtype=int)\n",
    "\n",
    "\n",
    "    # Draw the lines.\n",
    "    cv2.line(line_image, (lower_left_pt[0], lower_left_pt[1]), (upper_left_pt[0], upper_left_pt[1]), [255, 0, 0], 10)\n",
    "    cv2.line(line_image, (lower_right_pt[0], lower_right_pt[1]), (upper_right_pt[0], upper_right_pt[1]), [255, 0, 0], 10)\n",
    "    lines_edges = cv2.addWeighted(image, 0.8, line_image, 10, 0)\n",
    "    return lines_edges\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Video Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:02<00:00, 81.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 2.99 s, sys: 874 ms, total: 3.87 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "#Processing white video input\n",
    "\n",
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip= clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:08<00:00, 80.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 9.19 s, sys: 2.5 s, total: 11.7 s\n",
      "Wall time: 8.77 s\n"
     ]
    }
   ],
   "source": [
    "#Processing yellow video input\n",
    "\n",
    "yellow_output ='yellow.mp4'\n",
    "clip1 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "yellow_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Outputs annotated line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the processed video of white_output\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the processed video of yellow_output\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To view the raw lines output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image_raw(image):\n",
    "    \n",
    "     #Converting the image to grayscale\n",
    "    gray = grayscale(image)\n",
    "    \n",
    "    \n",
    "    #Applying gaussian blur to the grayscale image\n",
    "    kernel_size = 7\n",
    "    blur_gray = gaussian_blur(gray, kernel_size)\n",
    "    \n",
    "    \n",
    "    # Define our parameters for Canny and run it\n",
    "    low_threshold =50\n",
    "    high_threshold = 200\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold)\n",
    "\n",
    "    # Next we'll create a masked edges image using cv2.fillPoly()\n",
    "    \n",
    "    vertices_left = np.array([[(40,500),(390, 350), (500, 350), (500,500)]], dtype=np.int32)\n",
    "    vertices_right = np.array([[(940,500),(650, 350), (500, 350), (500,500)]], dtype=np.int32)\n",
    "   \n",
    "    masked_edges_left = region_of_interest(edges, vertices_left)\n",
    "    masked_edges_right = region_of_interest(edges, vertices_right)\n",
    "    \n",
    "        # Make a blank the same size as our image to draw on\n",
    "    rho = 2 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 10    # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length =10 #minimum number of pixels making up a line\n",
    "    max_line_gap = 15  # maximum gap in pixels between connectable line segments 15\n",
    "\n",
    "    line_image = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "  \n",
    "    \n",
    "    # Apply Hough's transform for left side and right side lines\n",
    "    hough_lines_left = hough_lines(masked_edges_left, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    hough_lines_right = hough_lines(masked_edges_right, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    \n",
    "    #Run linear regression for selected slope range \n",
    "    minY_right, maxY_right, m_right, c_right, line_image = linear_reg(hough_lines_right, 'r', line_image, 'raw')\n",
    "    minY_left, maxY_left, m_left, c_left, line_image = linear_reg(hough_lines_left, 'l',line_image, 'raw')\n",
    "    \n",
    "    # Determine the upper and lower points to draw a line in the image\n",
    "    min_y = np.min([minY_left, minY_right])\n",
    "    upper_right_pt = np.array([(min_y - c_right) / m_right, min_y], dtype=int)\n",
    "    upper_left_pt = np.array([(min_y - c_left) / m_left, min_y], dtype=int)\n",
    "    max_y = np.max([maxY_left,maxY_right])\n",
    "    lower_left_pt = np.array([(max_y - c_left) / m_left, max_y], dtype=int)\n",
    "    lower_right_pt = np.array([(max_y - c_right) / m_right, max_y], dtype=int)\n",
    "\n",
    "\n",
    "    # Draw the lines. the below lines are commented in the case of viewing the raw lines in the video output\n",
    "    #cv2.line(line_image, (lower_left_pt[0], lower_left_pt[1]), (upper_left_pt[0], upper_left_pt[1]), [255, 0, 0], 10)\n",
    "    #cv2.line(line_image, (lower_right_pt[0], lower_right_pt[1]), (upper_right_pt[0], upper_right_pt[1]), [255, 0, 0], 10)\n",
    "    lines_edges = cv2.addWeighted(image, 0.8, line_image, 10, 0)\n",
    "    return lines_edges\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw lines output for SolidWhiteRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white_raw.mp4\n",
      "[MoviePy] Writing video white_raw.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:02<00:00, 81.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white_raw.mp4 \n",
      "\n",
      "CPU times: user 3.01 s, sys: 871 ms, total: 3.88 s\n",
      "Wall time: 3.07 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white_raw.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_output = 'white_raw.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip= clip1.fl_image(process_image_raw) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "#View the processed video of white_output\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw lines output for SolidYellowLeft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow_raw.mp4\n",
      "[MoviePy] Writing video yellow_raw.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:08<00:00, 77.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow_raw.mp4 \n",
      "\n",
      "CPU times: user 9.46 s, sys: 2.58 s, total: 12 s\n",
      "Wall time: 9.12 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow_raw.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Processing yellow video input\n",
    "\n",
    "yellow_output ='yellow_raw.mp4'\n",
    "clip1 = VideoFileClip(\"solidYellowLeft.mp4\")\n",
    "yellow_clip = clip1.fl_image(process_image_raw) #NOTE: this function expects color images!!\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)\n",
    "\n",
    "#View the processed video of yellow_output\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
